{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Look up SMOTE oversampling  https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html \n",
    "# a. Describe what it is in your own words in markdown.\n",
    "# b. Use this technique with the diabetes dataset. Comment on the model performance compared to other methods. Make sure you are clear about why you chose the performance metric you did."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "SMOTE (Synthetic Minority Over-Sampling Technique) is a method to over sample the minority class in an imbalanced dataset so that the minority class can have the same or similar amount of samples as the majority class. SMOTE duplicates samples from existing samples in the minority class in the training dataset. \n",
    "\n",
    "A random sample from the minority class is chosen, then the k of the nearest neighbors to the random sample are found. A synthetic or duplicate example is created at a randomly selected point between the two examples in the feature space."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "diabetes_df = pd.read_csv('../week_13/diabetes.csv')\n",
    "diabetes_df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#checking the samples for each outcome: 0 (doesn't have diabetes) or 1 (does have diabetes)\n",
    "diabetes_df[\"Outcome\"].value_counts()\n",
    "\n",
    "#the classes are imbalanced"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# dividing data into X and y variables\n",
    "X = diabetes_df.drop('Outcome', axis=1) #features\n",
    "y = diabetes_df['Outcome'] #target\n",
    "\n",
    "# train_test_split\n",
    "# example of why to use stratify: https://machinelearningmastery.com/train-test-split-for-evaluating-machine-learning-algorithms/#:~:text=We%20can%20achieve%20this%20by,the%20provided%20%E2%80%9Cy%E2%80%9D%20array.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=24, stratify=y)\n",
    "\n",
    "#Standardize\n",
    "# you can standardize the X's before or after train_test_split\n",
    "sc = StandardScaler()\n",
    "X_train_scaler = sc.fit_transform(X_train)\n",
    "X_test_scaler = sc.fit_transform(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using SMOTE to handle the class imbalance"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#instantiate SMOTE\n",
    "smote = SMOTE(random_state = 24)\n",
    "#this is where we apply the resampling technique to our data\n",
    "#passing in the standardized data into the fit_resample function\n",
    "# leaving y_train as is because we don't need to standardize what we're trying to predict\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train_scaler, y_train)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "#train our model using resampled data. This done after preprocessing\n",
    "model = LogisticRegression(random_state=24)\n",
    "model.fit(X_resampled, y_resampled)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=24)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "#calculate accuracy\n",
    "#the balanced_accuracy score is assuming that the model is balanced\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "y_pred = model.predict(X_test_scaler)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7318518518518519"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from imblearn.metrics import classification_report_imbalanced\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.83      0.76      0.70      0.79      0.73      0.54       150\n",
      "          1       0.61      0.70      0.76      0.66      0.73      0.53        81\n",
      "\n",
      "avg / total       0.75      0.74      0.72      0.74      0.73      0.54       231\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### In comparison to the simpliest regression approach, SMOTE improved the true positives in recall, so it provides a better understanding of those who have diabetes. In comparison to the random over sampler approach, SMOTE does not perform as well in identifying  the true postives."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Create a function called rec_digit_sum that takes in an integer. This function is the recursive sum of all the digits in a number.\n",
    "\n",
    "## Given n, take the sum of all the digits in n. If the resulting value has more than one digit, continue calling the function in this way until a single-digit number is produced. The input will be a non-negative integer, and this should work for extremely large values as well as for single-digit inputs.\n",
    "Examples:\n",
    "\n",
    "16 --> 1+6=7\n",
    "\n",
    "942 --> 9+4+2=15 --> 1+5=6\n",
    "\n",
    "132189 --> 1+3+2+1+8+9=24 --> 2+4=6 493193 --> 4+9+3+1+9+3=29 --> 2+9=11"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "#https://www.geeksforgeeks.org/recursive-functions/\n",
    "\n",
    "def rec_digit_sum(n):\n",
    "    # create condition to return a single digit\n",
    "    if len(n)  == 1:\n",
    "        return int(n)\n",
    "    #base case for termination condition\n",
    "    total = 0\n",
    "    #create for loop to add all the digits in the number\n",
    "    for i in str(n):\n",
    "        total += int(i)\n",
    "\n",
    "    return rec_digit_sum(str(total))\n",
    "rec_digit_sum(str(16))\n",
    "rec_digit_sum(str(942))\n",
    "rec_digit_sum(str(547890))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}