{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eacd736",
   "metadata": {},
   "source": [
    "# 1. Write simple (straightforward) definitions for the following parameters for RandomForestClassifier (https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClass ifier.html) and indicate how they correlate with the precision and recall for the basic diabetes model we built in class. You will need to rerun the model multiple times to do so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ff8cd0d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix, classification_report, plot_confusion_matrix\n",
    "\n",
    "diabetes_df = pd.read_csv(\"../week_13/diabetes.csv\")\n",
    "diabetes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ad0ec11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/46480457/difference-between-min-samples-split-and-min-samples-leaf-in-sklearn-decisiontre\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = diabetes_df.drop('Outcome', axis=1)\n",
    "y = diabetes_df['Outcome']\n",
    "\n",
    "# Split into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42, stratify=y)\n",
    "\n",
    "#Standardize\n",
    "sc= StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "eb8f834e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7402597402597403"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#estimator = model\n",
    "rf = RandomForestClassifier(min_impurity_decrease = 0.03, random_state=42)\n",
    "\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "e47935c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.97      0.83       150\n",
      "           1       0.84      0.32      0.46        81\n",
      "\n",
      "    accuracy                           0.74       231\n",
      "   macro avg       0.78      0.64      0.65       231\n",
      "weighted avg       0.76      0.74      0.70       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = rf.predict(X_test)\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f61eed",
   "metadata": {},
   "source": [
    "**Parameter Definitions**\n",
    "\n",
    "n_estimators - the number of trees you want to build before taking the max. averages or predictions; higher number of trees give a better performance but slows down your code\n",
    "\n",
    "max_depth - the depth  every tree in random forest grows. It's the longest path between the root node and leaf node\n",
    "\n",
    "min_samples_split - tells the decision tree the minimum number of samples or observations any node needs in order to split further into subnodes\n",
    "\n",
    "min_samples_leaf - leaf is the end node of a decision tree. A smaller leaf makes the model more prone to capturing noise in train data. The minimum number of samples that should be present in the leaf node after splitting a node. Helps prevent overfitting as the parameter value increases\n",
    "\n",
    "min_weight_fraction_leaf - the fraction of the input samples required to be at a leaf node where weights are determined by sample_weight. This is a way to deal with class imbalance\n",
    "\n",
    "max_leaf_nodes - sets a condition on the splitting of the nodes in the tree and hence restricts the growth of the tree. \n",
    "\n",
    "min_impurity_decrease - controls how deep the tree grows based on the impurity. If the final impurity decrease is less than the minimum impurity decrease parameter, then the split will not be performed\n",
    "\n",
    "\n",
    "\n",
    "| Parameter | Correlation with Precision | Correlation with Recall |\n",
    "| --- | --- | --- |\n",
    "| n_estimator | positive: when set to 200, precision increased by 1% and 2% | negative: when set to 200, recall decreased by about 30% in correctly identifying those who have diabetes |\n",
    "| max_depth | positive: set to 9 precision increased by 1% and 2% when changed from its default | positive: increased by 1% for those who are non-diabetic and 3% for those who are diabetic\n",
    "| min_samples_split | positive when set to 6 it increases by 1% for those who are diabetic and 2% for non-diabetic | positive, increases by 1% and 3% in correctly identifying those who are diabetic\n",
    "| min_samples_leaf | positive: set to 4 precision increases by 1% and 2% | positive: increases by 1% and 3%\n",
    "| min_weight_fraction_leaf | positive or negative | positive or negative\n",
    "| max_leaf_nodes | positive when set to 20 | positive when set to 20\n",
    "| min_impurity_decrease | positive when set to 0.3, but anything lower creases the correlation | negative correlation indentifying diabetics when set to 0.3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9499a97b",
   "metadata": {},
   "source": [
    "#  2. How does setting bootstrap=False influence the model performance? Note: the default is bootstrap=True. Explain why your results might be so."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db292f75",
   "metadata": {},
   "source": [
    "**Setting bootstrap = False has a slight positive influence on the model performance. The accuracy improves by going from 75% to 76%. There is a slight decrease in recall when identifying those who are non-diabetic and precision increases when identifying those who are non-diabetic. Bootstrap set to false means that samples are drawn without replacement, so each data point or person in the dataset has only one chance to be selected in the sample.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f528d96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7489177489177489"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf1 = RandomForestClassifier(bootstrap = True, random_state=42)\n",
    "\n",
    "rf1 = rf1.fit(X_train, y_train)\n",
    "rf1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "606f68cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82       150\n",
      "           1       0.68      0.58      0.63        81\n",
      "\n",
      "    accuracy                           0.76       231\n",
      "   macro avg       0.74      0.72      0.72       231\n",
      "weighted avg       0.75      0.76      0.75       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = rf1.predict(X_test)\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593737ec",
   "metadata": {},
   "source": [
    "## Helpful links to review regarding parameters\n",
    "https://www.analyticsvidhya.com/blog/2020/03/beginners-guide-random-forest-hyperparameter-tuning/\n",
    "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "https://towardsdatascience.com/how-to-tune-a-decision-tree-f03721801680\n",
    "https://stackoverflow.com/questions/54812230/sklearn-min-impurity-decrease-explanation#:~:text=A%20node%20will%20be%20split,or%20equal%20to%20this%20value.&text=Does%20this%20mean%20to%20prune,will%20become%20less%20than%200.1%20%3F\n",
    "https://stackoverflow.com/questions/40131893/random-forest-with-bootstrap-false-in-scikit-learn-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58094e56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
